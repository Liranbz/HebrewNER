{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377.0
    },
    "colab_type": "code",
    "id": "d5nJycQ6Nsao",
    "outputId": "20a7d973-ed5a-4813-bc7b-95e0c1ff813c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval==0.0.5 in /usr/local/lib/python3.6/dist-packages (0.0.5)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval==0.0.5) (1.14.6)\n",
      "Requirement already satisfied: pytorch_pretrained_bert==0.4.0 in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.4.0) (1.14.6)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.4.0) (1.9.94)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.4.0) (1.0.1.post2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.4.0) (2.18.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert==0.4.0) (4.28.1)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert==0.4.0) (0.2.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert==0.4.0) (0.9.3)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.94 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert==0.4.0) (1.12.94)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert==0.4.0) (1.22)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert==0.4.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert==0.4.0) (2018.11.29)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert==0.4.0) (2.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.94->boto3->pytorch_pretrained_bert==0.4.0) (2.5.3)\n",
      "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.94->boto3->pytorch_pretrained_bert==0.4.0) (0.14)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.94->boto3->pytorch_pretrained_bert==0.4.0) (1.11.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval==0.0.5\n",
    "!pip install pytorch_pretrained_bert==0.4.0\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QQ9WyHjHOQpm"
   },
   "source": [
    "### Intro \n",
    "\n",
    "We'll try now a deep learning model using google bert, pytorch and tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gVLvpShQO7o-"
   },
   "source": [
    "First, let's again load our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QkpbqANBPFDL"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dataset_biluo.csv\", encoding=\"utf8\").fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dOl0ioZ5P-ql"
   },
   "source": [
    "Now, as bert expect sequences, let's create a sentence getter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TG2Jd3vQQOVh"
   },
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "\n",
    "    def __init__(self, data, max_sent=None):\n",
    "        self.index = 0\n",
    "        self.max_sent = max_sent\n",
    "        self.tokens = data[\"Token\"]\n",
    "        self.labels = data[\"BILUO\"]\n",
    "\n",
    "    def sentences(self):\n",
    "        sent = []\n",
    "        counter = 0\n",
    "\n",
    "        for token, label in zip(self.tokens, self.labels):\n",
    "            if token == \"DOCSTART\":\n",
    "                continue\n",
    "            sent.append((token, label))\n",
    "            if token.strip() == \".\":\n",
    "                yield sent\n",
    "                sent = []\n",
    "                counter += 1\n",
    "            if self.max_sent is not None and counter >= self.max_sent:\n",
    "                return\n",
    "\n",
    "    def get_next(self):\n",
    "        try:\n",
    "            while True:\n",
    "                sent = []\n",
    "                next_token = self.tokens[self.index]\n",
    "                if next_token == \"DOCSTART\":\n",
    "                    continue\n",
    "                next_label = self.labels[self.index]\n",
    "                sent.append((next_token, next_label))\n",
    "                self.index += 1\n",
    "                if next_token.strip() == \".\":\n",
    "                    return sent\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6YKLqvAPQYwR"
   },
   "source": [
    "Let's check our deep learning libraries are working properley:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68.0
    },
    "colab_type": "code",
    "id": "9zPDZdLEQe6y",
    "outputId": "fe1ec2c2-1610-41ee-ec80-9571b05be8be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Number of gpus: 1\n",
      "Name of gpu: Tesla K80\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "print(\"Device: \" + str(device))\n",
    "print(\"Number of gpus: \" + str(n_gpu))\n",
    "print(\"Name of gpu: \" + torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AWq2gJwOTDoO"
   },
   "source": [
    "We'll also add some constants that will determine the maximum sequence length and maximum batch sizes that we will feed the gpu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w-dm7-rWTJ4Q"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 75\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-EDusFH_RGlT"
   },
   "source": [
    "Next, let's get all of our sentences and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51.0
    },
    "colab_type": "code",
    "id": "AWCUKWd8RLho",
    "outputId": "20781b74-638d-47b5-938d-22455f194484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['אחד', 'מכל', 'שני', 'ישראלים', 'אוכלים', 'קורנפלקס', '.']\n",
      "['O', 'O', 'O', 'U-MISC', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "all_sentences = [[token for token, label in sent] for sent in getter.sentences()]\n",
    "all_orig_labels = [[label for token, label in sent] for sent in getter.sentences()]\n",
    "\n",
    "print(all_sentences[0])\n",
    "print(all_orig_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FQJAVeO2RdwO"
   },
   "source": [
    "Moving forward, we'll want to split our dataset into train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BRSLS-SIRhsa"
   },
   "outputs": [],
   "source": [
    "train_sentences, test_sentences, train_orig_labels, test_orig_labels = train_test_split(all_sentences, all_orig_labels, random_state=2018, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "32FCg00MRuoJ"
   },
   "source": [
    "As bert expects a tokenized sentence, we'll need to use the BertTokenizer with multilingual support. We'll create a function to achieve this. It's important to note that bert tend to split words, or as they call it, split into word pieces. Therefore, we'll need to update our labels arrays and expend them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71.0
    },
    "colab_type": "code",
    "id": "hxeQKHIsSTVM",
    "outputId": "28f1f611-9eb1-4ba6-9e38-7cba3861cb6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['כ', '##שר', '##ון', 'ה', '##די', '##בור', 'שלו', ',', 'ה', '##עו', '##מק', 'האי', '##נט', '##ל', '##קט', '##וא', '##לי', ',', 'ה', '##נע', '##ימות', 'ו', '##ה', '##ח', '##מי', '##מות', 'ש', '##כ', '##נע', '##ו', 'אנשים', 'רבים', 'ב', '##אר', '##ה', '\"', 'ב', 'שהוא', 'יהיה', 'יום', 'אחד', 'ה', '##ת', '##שוב', '##ה', 'ה', '##ד', '##מו', '##קר', '##טית', 'ל', '##רו', '##נל', '##ד', 'ר', '##יי', '##גן', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'U-LOC', 'U-LOC', 'U-LOC', 'U-LOC', 'U-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERS', 'B-PERS', 'B-PERS', 'B-PERS', 'L-PERS', 'L-PERS', 'L-PERS', 'O']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
    "\n",
    "def tokenize(sentences, orig_labels):\n",
    "    tokenized_texts = []\n",
    "    labels = []\n",
    "    for sent, sent_labels in zip(sentences, orig_labels):\n",
    "        bert_tokens = []\n",
    "        bert_labels = []\n",
    "        for orig_token, orig_label in zip(sent, sent_labels):\n",
    "            b_tokens = tokenizer.tokenize(orig_token)\n",
    "            bert_tokens.extend(b_tokens)\n",
    "            for b_token in b_tokens:\n",
    "                bert_labels.append(orig_label)\n",
    "        tokenized_texts.append(bert_tokens)\n",
    "        labels.append(bert_labels)\n",
    "\n",
    "        assert len(bert_tokens) == len(bert_labels)\n",
    "\n",
    "    return tokenized_texts, labels\n",
    "\n",
    "\n",
    "train_tokenized_texts, train_labels = tokenize(train_sentences, train_orig_labels)\n",
    "print(train_tokenized_texts[0])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uBzeYGHgSZ7r"
   },
   "source": [
    "Next we need to create sequences with padding to give to bert. We'll add first some utilties to convert labels into numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G1NcAaFbSnmF"
   },
   "outputs": [],
   "source": [
    "tags_vals = list(set(data[\"BILUO\"].values))\n",
    "tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
    "idx2tag = {i: t for i, t in enumerate(tags_vals)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-H79vf2hS0vs"
   },
   "source": [
    "Now, we can convert our sentences and labels into sequences with paddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f04k8SLBS-A-"
   },
   "outputs": [],
   "source": [
    "def pad_sentences_and_labels(tokenized_texts, labels):\n",
    "    input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                              maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
    "                         maxlen=MAX_LEN, value=tag2idx[\"O\"], padding=\"post\",\n",
    "                         dtype=\"long\", truncating=\"post\")\n",
    "\n",
    "    attention_masks = [[float(i>0) for i in ii] for ii in input_ids]\n",
    "    \n",
    "    return input_ids, tags, attention_masks\n",
    "  \n",
    "\n",
    "input_ids, tags, attention_masks = pad_sentences_and_labels(train_tokenized_texts, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SrXDvmUrTkWN"
   },
   "source": [
    "We're almost done. All that is left is to make tensors and  data loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iGy-clNDTx_w"
   },
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(input_ids)\n",
    "tr_tags = torch.tensor(tags)\n",
    "tr_masks = torch.tensor(attention_masks)\n",
    "\n",
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b_-uNK49T1ay"
   },
   "source": [
    "Now we're ready to create our bert model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884.0
    },
    "colab_type": "code",
    "id": "BCocK1v0T7fK",
    "outputId": "d3ef24e2-9a2d-47f0-b49a-420682fcb214"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   2%|▏         | 1/50 [01:21<1:06:15, 81.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5433959453194229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   4%|▍         | 2/50 [02:42<1:04:55, 81.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.20792146919318188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   6%|▌         | 3/50 [04:03<1:03:36, 81.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.13101311837449486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   8%|▊         | 4/50 [05:25<1:02:17, 81.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.09094174454609553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|█         | 5/50 [06:46<1:00:54, 81.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0648388571255369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  12%|█▏        | 6/50 [08:07<59:31, 81.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0480892972583756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  14%|█▍        | 7/50 [09:28<58:05, 81.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03666393825623356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  16%|█▌        | 8/50 [10:48<56:42, 81.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.031704388512873355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  18%|█▊        | 9/50 [12:09<55:19, 80.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.02821806796113558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 10/50 [13:30<53:56, 80.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.022489383529273817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  22%|██▏       | 11/50 [14:51<52:34, 80.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.020221201427004957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  24%|██▍       | 12/50 [16:12<51:13, 80.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.019611342269697307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  26%|██▌       | 13/50 [17:32<49:50, 80.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.01625634198375966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  28%|██▊       | 14/50 [18:53<48:29, 80.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.015636694246765087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|███       | 15/50 [20:14<47:08, 80.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.016578153270170277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  32%|███▏      | 16/50 [21:35<45:46, 80.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.01468606274517506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  34%|███▍      | 17/50 [22:56<44:25, 80.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.013702502580543544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  36%|███▌      | 18/50 [24:16<43:04, 80.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.014341677434133067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  38%|███▊      | 19/50 [25:37<41:44, 80.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.013777400193057586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 20/50 [26:58<40:23, 80.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.012922394686568252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  42%|████▏     | 21/50 [28:19<39:01, 80.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.011720016023810998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  44%|████▍     | 22/50 [29:39<37:39, 80.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.01294691033695859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  46%|████▌     | 23/50 [31:00<36:18, 80.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.011724586459164174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  48%|████▊     | 24/50 [32:20<34:58, 80.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.012008451855235538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████     | 25/50 [33:41<33:37, 80.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.01237493138587861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  52%|█████▏    | 26/50 [35:02<32:17, 80.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.011666864314817903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  54%|█████▍    | 27/50 [36:23<30:57, 80.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.01206289998896673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  56%|█████▌    | 28/50 [37:43<29:36, 80.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.011727892158461022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  58%|█████▊    | 29/50 [39:04<28:15, 80.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.011767537331634007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 30/50 [40:25<26:55, 80.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.011153251808682848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  62%|██████▏   | 31/50 [41:46<25:34, 80.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.010810013226647344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  64%|██████▍   | 32/50 [43:06<24:13, 80.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.011260053761631113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  66%|██████▌   | 33/50 [44:27<22:52, 80.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.01114532490329886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  68%|██████▊   | 34/50 [45:48<21:32, 80.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.011025763444464516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|███████   | 35/50 [47:09<20:11, 80.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.010447952828447645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  72%|███████▏  | 36/50 [48:30<18:50, 80.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.010628819428987938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  74%|███████▍  | 37/50 [49:50<17:29, 80.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.010998763333730123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  76%|███████▌  | 38/50 [51:11<16:08, 80.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.010311707571137375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  78%|███████▊  | 39/50 [52:32<14:47, 80.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.010557222495539642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████  | 40/50 [53:52<13:27, 80.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.011203645423836546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  82%|████████▏ | 41/50 [55:13<12:06, 80.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.009283937755641585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  84%|████████▍ | 42/50 [56:34<10:45, 80.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.009275855555092732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  86%|████████▌ | 43/50 [57:54<09:24, 80.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.009000133224303064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  88%|████████▊ | 44/50 [59:15<08:04, 80.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.011253994078243174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|█████████ | 45/50 [1:00:36<06:43, 80.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.010334758575212348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  92%|█████████▏| 46/50 [1:01:57<05:23, 80.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.009987548313802108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  94%|█████████▍| 47/50 [1:03:17<04:02, 80.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.010879647721684493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  96%|█████████▌| 48/50 [1:04:38<02:41, 80.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.010385963367298245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  98%|█████████▊| 49/50 [1:05:59<01:20, 80.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.009746180940886534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 100%|██████████| 50/50 [1:07:20<00:00, 80.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.009685530325823269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"bert-base-multilingual-uncased\", num_labels=len(tag2idx))\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters())\n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)\n",
    "\n",
    "from seqeval.metrics import f1_score\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # forward pass\n",
    "        loss = model(b_input_ids, token_type_ids=None,\n",
    "                     attention_mask=b_input_mask, labels=b_labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss / nb_tr_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O-RLt0brUNvh"
   },
   "source": [
    "Great, we now have a trained model. Let's test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102.0
    },
    "colab_type": "code",
    "id": "AJsv0lndURWz",
    "outputId": "aaa174d1-8fc4-4894-8047-72f357652dc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.14430818607174192\n",
      "Validation Accuracy: 0.9790873015873013\n",
      "F1-Score: 0.8195149464184996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def simplify_label(label):\n",
    "  if len(label.split(\"-\"))>1:\n",
    "    label = label.split(\"-\")[1]\n",
    "  return label\n",
    "\n",
    "def test_model():\n",
    "  classes_without_O = ['U-PERCENT', 'L-PERS', 'U-PERS', 'L-ORG', 'L-LOC', 'I-ORG', 'I-LOC', 'B-ORG', 'L-DATE', 'I-MONEY', 'B-MISC', 'L-MISC', 'L-MONEY', 'B-LOC', 'B-PERS', 'I-PERS', 'U-DATE', 'B-DATE', 'U-LOC', 'B-MONEY', 'U-MISC', 'I-MISC', 'I-DATE', 'L-PERCENT', 'I-TIME', 'U-ORG', 'L-TIME', 'B-PERCENT', 'B-TIME', 'U-TIME', 'I-PERCENT', 'U-MONEY' ]\n",
    "\n",
    "  test_tokenized_texts, test_labels = tokenize(test_sentences, test_orig_labels)\n",
    "  input_ids, tags, attention_masks = pad_sentences_and_labels(test_tokenized_texts, test_labels)\n",
    "\n",
    "  val_inputs = torch.tensor(input_ids)\n",
    "  val_tags = torch.tensor(tags)\n",
    "  val_masks = torch.tensor(attention_masks)\n",
    "\n",
    "  test_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "  test_sampler = SequentialSampler(test_data)\n",
    "  test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=bs)\n",
    "\n",
    "  model.eval()\n",
    "  eval_loss, eval_accuracy = 0, 0\n",
    "  nb_eval_steps, nb_eval_examples = 0, 0\n",
    "  predictions, true_labels = [], []\n",
    "  counter = 0\n",
    "  for batch in test_dataloader:\n",
    "      batch = tuple(t.to(device) for t in batch)\n",
    "      b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "      with torch.no_grad():\n",
    "          tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
    "                                attention_mask=b_input_mask, labels=b_labels)\n",
    "          logits = model(b_input_ids, token_type_ids=None,\n",
    "                         attention_mask=b_input_mask)\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      label_ids = b_labels.to('cpu').numpy()\n",
    "      predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "      true_labels.append(label_ids)\n",
    "\n",
    "      tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "      eval_loss += tmp_eval_loss.mean().item()\n",
    "      eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "      nb_eval_examples += b_input_ids.size(0)\n",
    "      nb_eval_steps += 1\n",
    "  eval_loss = eval_loss / nb_eval_steps\n",
    "  print(\"Validation loss: {}\".format(eval_loss))\n",
    "  print(\"Validation Accuracy: {}\".format(eval_accuracy / nb_eval_steps))\n",
    "  pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n",
    "  test_tags = [tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
    "  print(\"F1-Score: {}\".format(f1_score(pred_tags, test_tags)))\n",
    "\n",
    "  y_true = pd.Series(test_tags)\n",
    "  y_pred = pd.Series(pred_tags)\n",
    "  cross_tab = pd.crosstab(y_true, y_pred, rownames=['Real Label'], colnames=['Prediction'], margins=True)\n",
    "  report = classification_report(y_true, y_pred, labels=classes_without_O, target_names=classes_without_O)\n",
    "  report_with_O = classification_report(y_true, y_pred)\n",
    "\n",
    "  classes_without_O = ['DATE', 'LOC', 'MISC', 'MONEY', 'ORG', 'PERCENT', 'PERS', 'TIME']\n",
    "  t_y_true = [simplify_label(tags_vals[p_i]) for p in predictions for p_i in p]\n",
    "  t_y_pred = [simplify_label(tags_vals[l_ii]) for l in true_labels for l_i in l for l_ii in l_i]\n",
    "  \n",
    "  transformed_y_true = pd.Series(t_y_true)\n",
    "  transformed_y_pred = pd.Series(t_y_pred)\n",
    "\n",
    "  cross_tab_transformed = pd.crosstab(transformed_y_true, transformed_y_pred, rownames=['Real Label'], colnames=['Prediction'], margins=True)\n",
    "  report_transformed = classification_report(transformed_y_true, transformed_y_pred, labels=classes_without_O, target_names=classes_without_O)\n",
    "  report_with_O_transformed = classification_report(transformed_y_true, transformed_y_pred)\n",
    "  \n",
    "  return cross_tab, report, report_with_O, cross_tab_transformed, report_transformed, report_with_O_transformed\n",
    "\n",
    "#     print(test_tokenized_texts[0])\n",
    "#     print([idx2tag.get(i) for i in predictions[0]])\n",
    "#     print([idx2tag.get(i) for i in true_labels[0][0]])\n",
    "    \n",
    "\n",
    "cross_tab, report, report_with_O, cross_tab_transformed, report_transformed, report_with_O_transformed = test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680.0
    },
    "colab_type": "code",
    "id": "66viIHysTuUC",
    "outputId": "09d7cb41-a3ab-4d4e-bab9-8ce6ef258b78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   U-PERCENT       0.92      0.92      0.92        88\n",
      "      L-PERS       0.91      0.95      0.93       389\n",
      "      U-PERS       0.92      0.80      0.85       432\n",
      "       L-ORG       0.82      0.83      0.82       377\n",
      "       L-LOC       0.77      0.78      0.78       132\n",
      "       I-ORG       0.68      0.46      0.55        92\n",
      "       I-LOC       0.93      0.70      0.80        57\n",
      "       B-ORG       0.77      0.79      0.78       303\n",
      "      L-DATE       0.82      0.84      0.83       103\n",
      "     I-MONEY       0.90      1.00      0.95        28\n",
      "      B-MISC       0.69      0.59      0.63        41\n",
      "      L-MISC       0.84      0.57      0.68        63\n",
      "     L-MONEY       0.98      1.00      0.99        60\n",
      "       B-LOC       0.81      0.85      0.83       124\n",
      "      B-PERS       0.90      0.92      0.91       327\n",
      "      I-PERS       0.89      0.94      0.92        52\n",
      "      U-DATE       0.79      0.90      0.84       242\n",
      "      B-DATE       0.76      0.83      0.79        63\n",
      "       U-LOC       0.87      0.77      0.82       408\n",
      "     B-MONEY       0.93      0.96      0.95       227\n",
      "      U-MISC       0.96      0.93      0.94       382\n",
      "      I-MISC       1.00      0.27      0.42        49\n",
      "      I-DATE       0.79      0.62      0.70        24\n",
      "   L-PERCENT       1.00      0.92      0.96        13\n",
      "      I-TIME       0.00      0.00      0.00         0\n",
      "       U-ORG       0.82      0.69      0.75       306\n",
      "      L-TIME       0.78      1.00      0.88         7\n",
      "   B-PERCENT       0.92      0.97      0.95        36\n",
      "      B-TIME       1.00      1.00      1.00         2\n",
      "      U-TIME       0.50      0.33      0.40        21\n",
      "   I-PERCENT       1.00      1.00      1.00         1\n",
      "     U-MONEY       0.00      0.00      0.00        12\n",
      "\n",
      "   micro avg       0.86      0.83      0.84      4461\n",
      "   macro avg       0.80      0.75      0.77      4461\n",
      "weighted avg       0.86      0.83      0.84      4461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697.0
    },
    "colab_type": "code",
    "id": "-_MQ9a96UgTE",
    "outputId": "473c5013-0d2f-46d9-a2a5-a09eb4e221af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-DATE       0.76      0.83      0.79        63\n",
      "       B-LOC       0.81      0.85      0.83       124\n",
      "      B-MISC       0.69      0.59      0.63        41\n",
      "     B-MONEY       0.93      0.96      0.95       227\n",
      "       B-ORG       0.77      0.79      0.78       303\n",
      "   B-PERCENT       0.92      0.97      0.95        36\n",
      "      B-PERS       0.90      0.92      0.91       327\n",
      "      B-TIME       1.00      1.00      1.00         2\n",
      "      I-DATE       0.79      0.62      0.70        24\n",
      "       I-LOC       0.93      0.70      0.80        57\n",
      "      I-MISC       1.00      0.27      0.42        49\n",
      "     I-MONEY       0.90      1.00      0.95        28\n",
      "       I-ORG       0.68      0.46      0.55        92\n",
      "   I-PERCENT       1.00      1.00      1.00         1\n",
      "      I-PERS       0.89      0.94      0.92        52\n",
      "      I-TIME       0.00      0.00      0.00         0\n",
      "      L-DATE       0.82      0.84      0.83       103\n",
      "       L-LOC       0.77      0.78      0.78       132\n",
      "      L-MISC       0.84      0.57      0.68        63\n",
      "     L-MONEY       0.98      1.00      0.99        60\n",
      "       L-ORG       0.82      0.83      0.82       377\n",
      "   L-PERCENT       1.00      0.92      0.96        13\n",
      "      L-PERS       0.91      0.95      0.93       389\n",
      "      L-TIME       0.78      1.00      0.88         7\n",
      "           O       0.99      0.99      0.99     43689\n",
      "      U-DATE       0.79      0.90      0.84       242\n",
      "       U-LOC       0.87      0.77      0.82       408\n",
      "      U-MISC       0.96      0.93      0.94       382\n",
      "     U-MONEY       0.00      0.00      0.00        12\n",
      "       U-ORG       0.82      0.69      0.75       306\n",
      "   U-PERCENT       0.92      0.92      0.92        88\n",
      "      U-PERS       0.92      0.80      0.85       432\n",
      "      U-TIME       0.50      0.33      0.40        21\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     48150\n",
      "   macro avg       0.81      0.76      0.77     48150\n",
      "weighted avg       0.98      0.98      0.98     48150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report_with_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1132.0
    },
    "colab_type": "code",
    "id": "HvsQBwLXUhlA",
    "outputId": "3c21feb3-3e91-47d8-da8a-f6c5273a7e5e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prediction</th>\n",
       "      <th>B-DATE</th>\n",
       "      <th>B-LOC</th>\n",
       "      <th>B-MISC</th>\n",
       "      <th>B-MONEY</th>\n",
       "      <th>B-ORG</th>\n",
       "      <th>B-PERCENT</th>\n",
       "      <th>B-PERS</th>\n",
       "      <th>B-TIME</th>\n",
       "      <th>I-DATE</th>\n",
       "      <th>I-LOC</th>\n",
       "      <th>...</th>\n",
       "      <th>O</th>\n",
       "      <th>U-DATE</th>\n",
       "      <th>U-LOC</th>\n",
       "      <th>U-MISC</th>\n",
       "      <th>U-MONEY</th>\n",
       "      <th>U-ORG</th>\n",
       "      <th>U-PERCENT</th>\n",
       "      <th>U-PERS</th>\n",
       "      <th>U-TIME</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B-DATE</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-LOC</th>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-MISC</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-MONEY</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-ORG</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-PERCENT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-PERS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-TIME</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-DATE</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-LOC</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-MISC</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-MONEY</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-ORG</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-PERCENT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-PERS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-DATE</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-LOC</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-MISC</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-MONEY</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ORG</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-PERCENT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-PERS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-TIME</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>43412</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>43689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U-DATE</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U-LOC</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U-MISC</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U-MONEY</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U-ORG</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U-PERCENT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U-PERS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>344</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U-TIME</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>68</td>\n",
       "      <td>129</td>\n",
       "      <td>35</td>\n",
       "      <td>235</td>\n",
       "      <td>311</td>\n",
       "      <td>38</td>\n",
       "      <td>334</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>43872</td>\n",
       "      <td>277</td>\n",
       "      <td>365</td>\n",
       "      <td>368</td>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>88</td>\n",
       "      <td>375</td>\n",
       "      <td>14</td>\n",
       "      <td>48150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Prediction  B-DATE  B-LOC  B-MISC  B-MONEY  B-ORG  B-PERCENT  B-PERS  B-TIME  \\\n",
       "Real Label                                                                     \n",
       "B-DATE          52      0       0        0      0          0       0       0   \n",
       "B-LOC            0    105       2        0      1          0       0       0   \n",
       "B-MISC           0      0      24        0      0          0       0       0   \n",
       "B-MONEY          0      0       0      219      0          0       0       0   \n",
       "B-ORG            3      0       0        0    239          0       5       0   \n",
       "B-PERCENT        0      0       0        0      0         35       0       0   \n",
       "B-PERS           0      0       2        0      5          0     300       0   \n",
       "B-TIME           0      0       0        0      0          0       0       2   \n",
       "I-DATE           0      0       0        0      3          0       0       0   \n",
       "I-LOC            0      6       0        0      0          0       0       0   \n",
       "I-MISC           1      3       3        0      3          0       0       0   \n",
       "I-MONEY          0      0       0        0      0          0       0       0   \n",
       "I-ORG            0      1       0        0     10          0       0       0   \n",
       "I-PERCENT        0      0       0        0      0          0       0       0   \n",
       "I-PERS           0      0       0        0      0          0       0       0   \n",
       "L-DATE           0      0       0        0      0          0       0       0   \n",
       "L-LOC            0      1       0        0      0          0       0       0   \n",
       "L-MISC           0      0       0        0      0          0       0       0   \n",
       "L-MONEY          0      0       0        0      0          0       0       0   \n",
       "L-ORG            0      0       0        0      0          0       0       0   \n",
       "L-PERCENT        0      0       0        0      0          0       0       0   \n",
       "L-PERS           0      0       0        0      0          0       0       0   \n",
       "L-TIME           0      0       0        0      0          0       0       0   \n",
       "O               12     13       0        7     45          1      20       0   \n",
       "U-DATE           0      0       0        7      0          0       0       0   \n",
       "U-LOC            0      0       0        0      0          0       2       0   \n",
       "U-MISC           0      0       2        0      0          0       0       0   \n",
       "U-MONEY          0      0       0        2      0          0       0       0   \n",
       "U-ORG            0      0       0        0      5          0       0       0   \n",
       "U-PERCENT        0      0       0        0      0          2       0       0   \n",
       "U-PERS           0      0       2        0      0          0       7       0   \n",
       "U-TIME           0      0       0        0      0          0       0       0   \n",
       "All             68    129      35      235    311         38     334       2   \n",
       "\n",
       "Prediction  I-DATE  I-LOC  ...        O  U-DATE  U-LOC  U-MISC  U-MONEY  \\\n",
       "Real Label                 ...                                            \n",
       "B-DATE           1      0  ...        4       6      0       0        0   \n",
       "B-LOC            0      0  ...       16       0      0       0        0   \n",
       "B-MISC           0      0  ...       15       0      0       2        0   \n",
       "B-MONEY          0      0  ...        3       2      0       0        0   \n",
       "B-ORG            0      0  ...       45       0      0       0        0   \n",
       "B-PERCENT        0      0  ...        1       0      0       0        0   \n",
       "B-PERS           0      0  ...       15       0      0       0        0   \n",
       "B-TIME           0      0  ...        0       0      0       0        0   \n",
       "I-DATE          15      0  ...        0       0      0       0        0   \n",
       "I-LOC            0     40  ...        1       0      0       0        0   \n",
       "I-MISC           0      0  ...       21       0      0       0        0   \n",
       "I-MONEY          0      0  ...        0       0      0       0        0   \n",
       "I-ORG            0      0  ...       25       0      0       0        0   \n",
       "I-PERCENT        0      0  ...        0       0      0       0        0   \n",
       "I-PERS           0      0  ...        1       0      0       0        0   \n",
       "L-DATE           2      0  ...        3       1      0       0        0   \n",
       "L-LOC            0      2  ...       18       0      6       0        0   \n",
       "L-MISC           0      0  ...       13       0      0       1        0   \n",
       "L-MONEY          0      0  ...        0       0      0       0        0   \n",
       "L-ORG            0      0  ...       45       0      0       0        0   \n",
       "L-PERCENT        0      0  ...        0       0      0       0        0   \n",
       "L-PERS           0      0  ...       11       0      0       0        0   \n",
       "L-TIME           0      0  ...        0       0      0       0        0   \n",
       "O                1      1  ...    43412      29     28       3        1   \n",
       "U-DATE           0      0  ...       16     219      0       0        0   \n",
       "U-LOC            0      0  ...       62       0    316       1        0   \n",
       "U-MISC           0      0  ...       20       0      0     354        0   \n",
       "U-MONEY          0      0  ...        3       7      0       0        0   \n",
       "U-ORG            0      0  ...       57       0     15       7        0   \n",
       "U-PERCENT        0      0  ...        5       0      0       0        0   \n",
       "U-PERS           0      0  ...       59       0      0       0        0   \n",
       "U-TIME           0      0  ...        1      13      0       0        0   \n",
       "All             19     43  ...    43872     277    365     368        1   \n",
       "\n",
       "Prediction  U-ORG  U-PERCENT  U-PERS  U-TIME    All  \n",
       "Real Label                                           \n",
       "B-DATE          0          0       0       0     63  \n",
       "B-LOC           0          0       0       0    124  \n",
       "B-MISC          0          0       0       0     41  \n",
       "B-MONEY         0          0       0       0    227  \n",
       "B-ORG           4          0       0       0    303  \n",
       "B-PERCENT       0          0       0       0     36  \n",
       "B-PERS          0          0       5       0    327  \n",
       "B-TIME          0          0       0       0      2  \n",
       "I-DATE          0          0       0       0     24  \n",
       "I-LOC           0          0       0       7     57  \n",
       "I-MISC          2          0       0       0     49  \n",
       "I-MONEY         0          0       0       0     28  \n",
       "I-ORG           3          0       0       0     92  \n",
       "I-PERCENT       0          0       0       0      1  \n",
       "I-PERS          0          0       0       0     52  \n",
       "L-DATE          4          0       0       0    103  \n",
       "L-LOC           0          0       0       0    132  \n",
       "L-MISC          1          0       0       0     63  \n",
       "L-MONEY         0          0       0       0     60  \n",
       "L-ORG           0          0       0       0    377  \n",
       "L-PERCENT       0          1       0       0     13  \n",
       "L-PERS          0          0       5       0    389  \n",
       "L-TIME          0          0       0       0      7  \n",
       "O              24          6      16       0  43689  \n",
       "U-DATE          0          0       0       0    242  \n",
       "U-LOC           4          0       3       0    408  \n",
       "U-MISC          0          0       0       0    382  \n",
       "U-MONEY         0          0       0       0     12  \n",
       "U-ORG         211          0       2       0    306  \n",
       "U-PERCENT       0         81       0       0     88  \n",
       "U-PERS          5          0     344       0    432  \n",
       "U-TIME          0          0       0       7     21  \n",
       "All           258         88     375      14  48150  \n",
       "\n",
       "[33 rows x 34 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s044h2IggQm1"
   },
   "source": [
    "Now, let's simplify the tags to use 'report per chunk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272.0
    },
    "colab_type": "code",
    "id": "yAgSM9gdgNm4",
    "outputId": "b08e9bb3-d0b7-42b2-f6d1-d314c642ae86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DATE       0.90      0.83      0.86       470\n",
      "         LOC       0.83      0.90      0.86       670\n",
      "        MISC       0.82      0.96      0.88       459\n",
      "       MONEY       0.95      0.95      0.95       328\n",
      "         ORG       0.80      0.85      0.82      1013\n",
      "     PERCENT       0.96      0.95      0.95       139\n",
      "        PERS       0.91      0.94      0.92      1170\n",
      "        TIME       0.53      0.55      0.54        29\n",
      "\n",
      "   micro avg       0.86      0.90      0.88      4278\n",
      "   macro avg       0.84      0.86      0.85      4278\n",
      "weighted avg       0.86      0.90      0.88      4278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289.0
    },
    "colab_type": "code",
    "id": "4cD675SsgWx1",
    "outputId": "529226eb-629e-4ec3-c4f9-c3419be825ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DATE       0.90      0.83      0.86       470\n",
      "         LOC       0.83      0.90      0.86       670\n",
      "        MISC       0.82      0.96      0.88       459\n",
      "       MONEY       0.95      0.95      0.95       328\n",
      "           O       0.99      0.99      0.99     43872\n",
      "         ORG       0.80      0.85      0.82      1013\n",
      "     PERCENT       0.96      0.95      0.95       139\n",
      "        PERS       0.91      0.94      0.92      1170\n",
      "        TIME       0.53      0.55      0.54        29\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     48150\n",
      "   macro avg       0.86      0.88      0.87     48150\n",
      "weighted avg       0.98      0.98      0.98     48150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report_with_O_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390.0
    },
    "colab_type": "code",
    "id": "HaU03Ao0gXQ9",
    "outputId": "a8e6a01d-a725-444b-c6b1-309241e99456"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prediction</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LOC</th>\n",
       "      <th>MISC</th>\n",
       "      <th>MONEY</th>\n",
       "      <th>O</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PERCENT</th>\n",
       "      <th>PERS</th>\n",
       "      <th>TIME</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>388</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISC</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>439</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONEY</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>23</td>\n",
       "      <td>97</td>\n",
       "      <td>69</td>\n",
       "      <td>6</td>\n",
       "      <td>43412</td>\n",
       "      <td>172</td>\n",
       "      <td>6</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>43872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>858</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERCENT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERS</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1095</td>\n",
       "      <td>0</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIME</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>432</td>\n",
       "      <td>721</td>\n",
       "      <td>535</td>\n",
       "      <td>327</td>\n",
       "      <td>43689</td>\n",
       "      <td>1078</td>\n",
       "      <td>138</td>\n",
       "      <td>1200</td>\n",
       "      <td>30</td>\n",
       "      <td>48150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prediction  DATE  LOC  MISC  MONEY      O   ORG  PERCENT  PERS  TIME    All\n",
       "Real Label                                                                 \n",
       "DATE         388    0     3      9     51     6        0     0    13    470\n",
       "LOC            0  600     7      0     45    16        0     2     0    670\n",
       "MISC           0    4   439      0      5     7        0     4     0    459\n",
       "MONEY          7    0     0    312      9     0        0     0     0    328\n",
       "O             23   97    69      6  43412   172        6    86     1  43872\n",
       "ORG           10    8    17      0    107   858        0    13     0   1013\n",
       "PERCENT        0    0     0      0      7     0      132     0     0    139\n",
       "PERS           0    5     0      0     51    19        0  1095     0   1170\n",
       "TIME           4    7     0      0      2     0        0     0    16     29\n",
       "All          432  721   535    327  43689  1078      138  1200    30  48150"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_tab_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qMqp3rHmfG-f"
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "We presented a deep learning method using bert for learning the NER task in hebrew and we got better results\n",
    "than previous methods. Awesome !!!\n",
    "\n",
    "\n",
    "Hope you had fun ✋ "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Phase3_DL.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
